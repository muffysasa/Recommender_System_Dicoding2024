# -*- coding: utf-8 -*-
"""Rev Final of Recommender_system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zRrRuSCgArZo7sZfypszXhzNqb1hJz4t

##Laporan Proyek 2 Recommendation System Machine Learning - Makrufiah Sakatri

### 1. Project Overview

Destinasi wisata adalah tujuan yang dikunjungi baik oleh wisatawan lokal maupun internasional untuk liburan atau menikmati pesona alam, budaya, dan atraksi tertentu. Setiap destinasi memiliki daya tarik dan keunikan tersendiri, seperti keindahan alam, nilai sejarah, atau aktivitas menarik yang dapat menghibur pengunjung.

Indonesia sendiri memiliki ratusan hingga ribuan destinasi wisata alam dan budaya yang kaya, sehingga banyak menarik perhatian wisatawan baik lokal dan mancanegara untuk menikmati khas alam dan budaya di Indonesia. Sektor wisata dengan keragaman alam bidaya di Indonesia dapat meningkatkan perekonomian Indonesia. Sehingga penting bagi pihak destinasi wisata di Indonesia untuk meningkatkan dan mempertahankan wisatawan baik lokal maupun mancanegara menjadikan destinasi wisata di Indonesia merupakan destinasi yang terbaik

Setiap wisatawan memiliki preferensi atraksi atau keunikan yang ingin dinikmati. Banyak calon wisatawan ingin mencoba atau mendatangi wisata yang baru atau memiliki review yang baik. Seringkali calon turis menentukan tujuan destinasinya berdasarkan pengalaman bagi turis yang memiliki riwayat kunjungan ke wisata tersebut. Namun karena banyaknya jenis dan lokasi wisata di Indonesia maka akan terlalu banyak informasi yang didapat dan kurang tepat sasaran pada calon turis sesuai preferensinya tersebut. Dengan perkembangan Machine learning, faktor tersebut dapat dibantu dengan membangun sistem yang dapat menilai atau merekomendasikan tujuan wisata sesuai dengan ciri khas yang diinginkan oleh pengunjung [referensi jurnal](http://jurnal.upnyk.ac.id/index.php/telematika/article/view/3023/2443).

### 2. Business Understanding

**- Problem Statement**

Indonesia memiliki ragam wisata yang didatangi banyak wisatawan. Dengan keragaman wisata dan banyaknya wisatawan dapat menghasilkan Data Mining yang merekam data-data transaksi wisatawan berkunjung di Indonesia. Sehingga, dapat dimanfaatkan untuk membangun sistem rekomendasi bertujuan menggali informasi dan mencari wisatawan baru.
Selain itu, banyak wisatawan mendatangi destinasi wisata sesuai dengan preferensi mereka, agar tujuan yang didatangi dapat memenuhi ekspetasi. Perlu adanya sistem rekomendasi yang dapat membaca preferensi calon wisatawan dan menyesuaikan referensi wisatawan lainnya yang memiliki riwayat menikmati wisata yang sama dengan preferensi calon wisatawan. Sehingga rekomendasi wisata akan menyesuaikan dengan preferensi calon wisatawan, dapat meningkatkan ekspetasi setelah berkunjung sesuai rekomendasi dan juga dapat menaikkan daya tarik wisata yang dapat meningkatkan perekonomian Indonesia.


Berdasarkan latar belakang tersebut project ini memiliki batasan masalah sebagai berikut:
1. **Bagaimana langkah-langkah untuk membuat sistem rekomendasi untuk calon pengunjung berdasarkan referensi riwayat pengunjung?**
  --> Melakukan metode sederhana CRISP-DM (Cross-Industry Standard Process for Data Mining) yaitu mengumpulkan, membersihkan dan menganalisis data. selanjutnya melakukan fitur engineering untuk membangun model sistem rekomendasi.
2. **Bagaimana atribut-atribut referensi pengunjung-pengunjung untuk menentukan destinasi wisata?**
  --> Menganalisis referensi data pengunjung wisata sebagai penilaian destinasi wisata
3. **Bagaimana cara membangun model Machine Learning sebagai solusi untuk merekomendasikan destinasi wisata untuk calon pengunjung berdasarakan preferensi pengunjung tersebut?**
  --> Analisis data dan membangun model menggunakan Deep Learning dengan eksplorasi hyperparameter berdasarkan rating dan ciri khas destinasi wisata melihat pada MSE, MAE dan R2 sebagai parameter model yang memiliki error paling kecil

  
**- Goals**

Sistem rekomendasi destinasi wisata bertujuan bagi calon pengunjung untuk:
1.   **Merekomendasikan tujuan wisata sesuai prefernsinya berdasarkan referensi riwayat pengunjung-pengunjung sebelumnya yang memiliki kesamaan preferensi tujuan wisata**
2.   **Menilai referensi pengunjung untuk menentukan destinasi wisata**,
3.  **Meningkatkan kepuasan para pengunjung wisaata sesuai preferensinya**,
4. **Mengurangi penilaian rendah pada destinasi wisata karena kurang sesuainya terhadap preferensi calon pengunjung**

**- Solution statements**
Menggunakan content based filtering cosine similarity, collaborative filtering algoritma recommenderNet dengan library keras dan SVD dengan library surprise yang dapat terukur baik menggunakan RMSE dan MAE

### 3. Data Understanding

Data yang digunakan bersumber [Mendeley Data](https://data.mendeley.com/datasets/h58s544674/1), oleh kontributor *huda, choirul huda (2023), “Tourism Dataset”, Mendeley Data, V1, doi: 10.17632/h58s544674.1*. Data tersebut berisi transaksi turis pada 3 lokasi wisata yang terpopuler di Indonesia yaitu Bali, Malang dan Yogyakarta dari riwayat turis yang direkam oleh website TripAdvisor rentang waktu Oktober 2022 - January 2023. Data terdapat 9 data format xlsx. Berikut penjelasan kolom-kolom pada masing-masing data:

1. Data City.xlsx -> master data kota persona turis. [9143 baris, 3 kolom]
  - CityId : integer berisi identifikasi unik merepresentasikan sebuah kota | 9143 non-null
  - CityName : string berisi informasi nama kota | 9142 non-null
  - CountryId : integer berisi identifikasi unik merepresentasikan sebuah negara |9143 non-null

  Data terdapat nilai null, namun tabel ini tidak diperlukan drop data karena akan digunakan referensi dari penggabungan data.
2. Data Continent.xlsx -> master data benua persona turis. [6 kolom, 2 baris]
  - ContenetId : integer berisi identifikasi unik merepresentasikan sebuah benua | 6 non-null
  - Contenent : string berisi informasi nama benua | 6 non-null

  Tidak ada nilai null
3. Data Country.xlsx -> master data negara persona turis. [165 baris, 3 kolom]
  - CountryId : integer berisi identifikasi unik merepresentasikan sebuah negara | 165 non-null
  - Country : sting berisi informasi nama wilayah | 165 non-null
  - RegionId : integer berisi identifikasi unik merepresentasikan sebuah wilayah | 165 non-null

  Tidak ada nilai null
4. Data Item.xlsx -> master data destinasi wisata. [30 baris, 5 kolom
  - Attractionid : integer berisi identifikasi unik merepresentasikan sebuah wisata | 30 non-null
  - AttractionCityId : integer berisi identifikasi unik merepresentasikan sebuah lokasi kota wisata | 30 non-null
  - AttractionTypeId : integer berisi identifikasi unik merepresentasikan sebuah tipe wisata | 30 non-null
  - Attraction : string berisi informasi nama wisata |  30 non-null
  - AttractionAddress : string berisi informasi alamat wisata | 30 non-null

  Tidak ada nilai null
5. Data Mode.xlsx -> master data jenis kunjungan turis. [6 baris, 2 kolom]
  - VisitModeId : integer berisi identifikasi unik merepresentasikan sebuah jenis kunjungan wisatawan | 6 non-null
  - VisitMode : string berisi informasi jenis kunjungan wisatawan |  6 non-null

  Tidak ada nilai null, namun pada visit mode terdapat nilai tidak konsisten yaitu nilai "-". Hal ini tidak perlu di drop karena akan digunakan referensi penggabungan data
6. Data Region.xlsx -> master data daerah persona turis. [22 baris, 3 kolom]
  - Region : string berisi informasi nama negara | 22 non-null
  - RegionId : integer berisi identifikasi unik merepresentasikan sebuah negara | 22 non-null
  - ContentId : integer berisi identifikasi unik merepresentasikan sebuah benua | 22 non-null

  Tidak ada nilai null
7. Data Transaction.xlsx -> data transaksi turis. [52930 baris,7 kolom]
  - TransactionId : integer berisi identifikasi unik merepresentasikan sebuah transaksi | 52930 non-null
  - UserId : integer berisi identifikasi unik merepresentasikan sebuah user/wisatawan | 52930 non-null
  - VisitYear : datetime informasi waktu tahun kunjungan wisatawan | 52930 non-null
  - VisitMonth : datetime informasi waktu bulan kunjungan wisatawan | 52930 non-null
  - VisitMode : string berisi informasi jenis kunjungan wisatawan | 52930 non-null
  - AttractionId : integer berisi identifikasi unik merepresentasikan sebuah wisata | 52930 non-null
  - Rating : integer berisi informasi rating wisatawan terhadap tempat wisata (ordinal)| 52930 non-null

  Tidak ada nilai null
8. Data Type.xlsx -> master data tipe wisata. [17 baris, 2 kolom]
  - AttractionTypeId : integer berisi identifikasi unik merepresentasikan sebuah jenis wisata | 7 non-null
  - AttractionType : string berisi informasi nama jenis wisata | 7 non-null

  Tidak ada nilai null
9. Data User.xlsx -> data referesni persona turis. [33530 baris, 5 kolom]
  - UserId : integer berisi identifikasi unik merepresentasikan sebuah user/wisatawan |33530 non-null
  - ContenentId : integer berisi identifikasi unik merepresentasikan sebuah benua | 33530 non-null
  - RegionId : integer berisi identifikasi unik merepresentasikan sebuah wilayah | 33530 non-null
  - CountryId : integer berisi identifikasi unik merepresentasikan sebuah negara | 33530 non-null
  - CityId : integer berisi identifikasi unik merepresentasikan sebuah kota |33526 non-null
  
  Data terdapat nilai null, namun tabel ini tidak diperlukan drop data karena akan digunakan referensi dari penggabungan data.


Pada informasi masing-masing data terdapat nilai null. Pembersihan data/drop data akan dilakukan setelah penggabungan data/merge data

##### 3.1 Menkonversi folder data zip
"""

!unzip /content/Tourism_Dataset.zip

"""##### 3. 2 Melihat nama-nama file data"""

import os
print("jumlah file data: ", len(os.listdir('/content/Tourism Dataset')))
n = 0
for i in os.listdir('/content/Tourism Dataset'):
    n+=1
    print(n,i)

"""##### 3. 3 Membuat variabel data"""

!pip install openpyxl # library untuk membaca file excel
import pandas as pd

region = pd.read_excel('/content/Tourism Dataset/Region.xlsx')
user = pd.read_excel('/content/Tourism Dataset/User.xlsx')
type = pd.read_excel('/content/Tourism Dataset/Type.xlsx')
transaction = pd.read_excel('/content/Tourism Dataset/Transaction.xlsx')
country = pd.read_excel('/content/Tourism Dataset/Country.xlsx')
continent = pd.read_excel('/content/Tourism Dataset/Continent.xlsx')
item = pd.read_excel('/content/Tourism Dataset/Item.xlsx')
city = pd.read_excel('/content/Tourism Dataset/City.xlsx')
mode = pd.read_excel('/content/Tourism Dataset/Mode.xlsx')

"""##### 3. 4 Melihat isi variabel keseluruhan data, jumlah data pada kolom, melihat isi data setiap kolom"""

def show_data(file):
  print('jumlah baris dan kolom:', file.shape)
  print('='*80)
  print(file.info())
  print('='*80)
  return file.head(5)

"""###### 3. 4. 1 Data Region"""

show_data(region)

print("panjang nilai unik Region:",len(region['Region'].unique()))
region['Region'].unique()



"""###### 3. 4. 2 Data User"""

show_data(user)

"""###### 3. 4. 3 Data Type"""

show_data(type)

print("panjang nilai unik Region:",len(type['AttractionType'].unique()))
type['AttractionType'].unique()

"""###### 3. 4. 4 Data Transaction"""

show_data(transaction)

"""###### 3. 4. 5 Data Country"""

show_data(country)

print("panjang nilai unik Region:",len(country['Country'].unique()))
country['Country'].unique()

"""###### 3. 4. 6 Data Continent"""

show_data(continent)

print("panjang nilai unik Region:",len(continent['Contenent'].unique()))
continent['Contenent'].unique()

"""###### 3. 4. 7 Data City"""

show_data(city)

print("panjang nilai unik Region:",len(city['CityName'].unique()))
city['CityName'].unique()

"""###### 3. 4. 8 Data Mode"""

show_data(mode)

print("panjang nilai unik Region:",len(mode['VisitMode'].unique()))
mode['VisitMode'].unique()

"""###### 3. 4. 9 Data Item"""

show_data(item)

"""##### 3. 5 Data Processing

Berdasarkan data understanding bahwa folder Tourism_Dataset terdapat 9 file. Pada tahap ini, akan dilakukan proses penggabungan data menampilkan informasi yang konsisten. Merge data destinasi wisata berisi informasi tujuan wisata berdasarkan lokasi, type wisata, kunjungan dsb

###### 3. 5. 1 Merge data destination -> data yang akan digunakan adalah transaksi pada destinasi
"""

item_joined = pd.merge(item, type , on='AttractionTypeId', how='left')
item_joined

transaction_joined = pd.merge(transaction, item_joined , on='AttractionId', how='left')
transaction_joined

transaction_joined = transaction_joined.rename(columns={'VisitMode': 'VisitModeId'})
transaction_joined

transaction_joined_2 = pd.merge(transaction_joined, mode , on='VisitModeId', how='left')
transaction_joined_2

"""###### 3. 5. 2 Melihat informasi penggabungan data destinasi wisata"""

transaction_joined_2.info()

"""Berdasarkan informasi diatas tidak ada data Null/kosong. Pada sebelumnya tabel data-data yang terdapat nilai null tidak dirujuk oleh data yang dimerge. Sehingga data setelah dimerge/digabung semua berisi nilai semua

###### 3. 5. 3 Melihat data yang duplikat
"""

transaction_joined_2.duplicated().sum()

"""Tidak ada nilai duplikat

###### 3. 5. 4 Data Processing -> untuk metode content based

Data untuk rekomendasi sistem content based berdasarkan kesamaan item satu antar lainnya yang didapatkan dari data unik sebuah item. Item yang akan digunakan yaitu Attraction. Maka data akan berisi nilai unik Attraction saja.
"""

data_use_1 =transaction_joined_2.copy()
data_use_1

print("jumlah banyak data unik jenis wisata (AttractionType)= ", len(data_use_1.AttractionType.unique()))
print("jumlah banyak data unik wisata (Attraction)=",len(data_use_1.Attraction.unique()))
print("jumlah banyak data unik mode wisata (VisitMode)=",len(data_use_1.VisitMode.unique()))

"""Membuat data berdasarkan nilai unik baru 2 item yaitu tipe wisata dan mode wisata"""

data_use_2 = data_use_1.drop_duplicates('Attraction')
data_use_2

"""Membuat variabel data frame untuk Data Preparation sistem rekomendasi content based"""

df_content = data_use_2[['Attraction',	'AttractionAddress',	'AttractionType']]
df_content = df_content.reset_index(drop=True)
df_content

"""###### 3. 5. 5 Data Processing -> untuk metode collaborative based

Data untuk rekomendasi sistem collaborative based akan berdasarkan rating

Menginstall library yang akan digunakan
"""

# Import library
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

data_use_rating = transaction_joined_2.copy()
data_use_rating.sort_values(by=['TransactionId'], inplace=True)
data_use_rating

"""##### 3. 6 EDA dan visualisasi"""

print("jumlah nilai unuk wisata: ", len(data_use_rating['Attraction'].unique()))

"""###### EDA melihat jumlah tempat wisata yang dikunjungi turis -> rentang Oktober 2022 - Januari 2023"""

att = data_use_rating['Attraction'].value_counts().sort_values(ascending =True)
plt.figure(figsize=(15, 6))
plt.barh(att.index, att.values, color='orchid')
plt.ylabel('Type')
plt.xlabel('Count')
plt.title('Attraction Top Places')
plt.show()

"""5 favorit destinasi wisata dengan jumlah pengunjung wisata terbanyak terdapat pada tempat wisata Bali:
- Sacred Monkey Forest Sactuary = ±13000 pengunjung
- Waterbom Bali = ±7000 pengunjung
- Tegalalang Rice Terrace = ±5800 pengunjung
- Uluwatu temple = ±3800 pengunjung
- Tanah Lot Temple = ±3800 pengunjung

##### EDA melihat jumlah rating -> keseluruhan destinasi wisata di Indonesia
"""

rate = data_use_rating['Rating'].value_counts().sort_values(ascending =True)
plt.figure(figsize=(10, 6))
plt.bar(rate.index, rate.values, color=['crimson', 'deeppink', 'mediumorchid', 'blueviolet','darkslateblue'])  # Menggunakan plt.barh untuk bar chart horizontal
plt.ylabel('Type')  # Label untuk sumbu y
plt.xlabel('Count')  # Label untuk sumbu x
plt.title('Total Rating Wisata di Indonesia')
plt.show()

"""Keseluruhan tempat wisata di Indonesia didominasi rating 5. Sehingga, wisata-wisata Indonesia merupakan destinasi wisatawan yang menyenangkan.

##### EDA melihat jumlah rating -> masing-masing wisata Indenesia (yang banyak dikunjungi wisatawan)

Mengkonversi data menggunakan cross tab sehingga nilai freskuensi pada masing-masing nilai kolom yang ditentukan
"""

import pandas as pd
rate_10 = data_use_rating
crosstab_count = pd.crosstab(rate_10['Attraction'], rate_10['Rating'])
crosstab_count['count'] = crosstab_count.sum(axis=1)
crosstab_count.sort_values(by='count', ascending=False, inplace=True)
crosstab_count

att_all = crosstab_count.drop(columns='count')

att_all.plot(kind='bar', figsize=(12, 8), width=0.8, color=['crimson', 'deeppink', 'mediumorchid', 'blueviolet','darkslateblue'])
plt.title('Distribusi Rating per Attraction (0-9)', fontsize=16)
plt.xlabel('Attraction', fontsize=12)
plt.ylabel('Jumlah', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.legend(title='Rating')


plt.tight_layout()
plt.show()

"""Berdasarkan visualisasi, 5 wisata di Bali dengan  jumlah pengunjung terbanyak memiliki jumlah rating diatas 3 banyak. Dapat disimpulkan Bali merupakan destinasi wisata favorit.

##### EDA melihat mode kunjungan -> keseluruhan wisata
"""

mode_visit = data_use_rating['VisitMode'].value_counts()

colors = ['pink', 'thistle', 'palevioletred', 'purple', 'indigo']
plt.figure(figsize=(10, 5.8))
plt.pie(mode_visit.values, labels=mode_visit.index, colors=colors,
autopct='%1.1f%%', shadow=True, startangle=140, wedgeprops=dict(width=0.6))
plt.axis('equal')
plt.show()

"""Mode kunjungan wisata di Indonesia didominasi pengunjung dengan kategori Couple/pasangan yaitu 40.8%

##### EDA melihat mode kunjungan tiap daerah -> Bali, Malang, Jawa Tengah
"""

mode_visit_1 = data_use_rating[data_use_rating['AttractionCityId'] ==1]
mode_visit_2 = data_use_rating[data_use_rating['AttractionCityId'] ==2]
mode_visit_3 = data_use_rating[data_use_rating['AttractionCityId'] ==3]
mode_visit_1 = mode_visit_1['VisitMode'].value_counts() #Bali
mode_visit_2 = mode_visit_2['VisitMode'].value_counts() #Malang
mode_visit_3 = mode_visit_3['VisitMode'].value_counts() #Jawa

fig, axs = plt.subplots(1, 3, figsize=(18, 6))


colors = ['pink', 'thistle', 'palevioletred', 'purple', 'indigo']
#axs[0].figure(figsize=(10, 5.8))
axs[0].set_title('Diagram jumlah kunjungan di Bali', fontsize=16) # Use set_title to set the title
axs[0].pie(mode_visit_1.values, labels=mode_visit_1.index, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140, wedgeprops=dict(width=0.6))
axs[0].axis('off')


axs[1].set_title('Diagram jumlah kunjungan di Jawa Timur (Malang)', fontsize=16) # Use set_title to set the title
axs[1].pie(mode_visit_2.values, labels=mode_visit_2.index, colors=colors,
autopct='%1.1f%%', shadow=True, startangle=140, wedgeprops=dict(width=0.6))
axs[1].axis('off')


axs[2].set_title('Diagram jumlah kunjungan di DI Yogyakarta (Area Yogyakarta)', fontsize=16) # Use set_title to set the title
axs[2].pie(mode_visit_3.values, labels=mode_visit_3.index, colors=colors,
autopct='%1.1f%%', shadow=True, startangle=140, wedgeprops=dict(width=0.6))
axs[2].axis('off')
plt.tight_layout()
plt.show()

"""- Wisata di Bali merupakan cocok untuk mode kunjungan wisatawan Couple dilihat dari diagram diatas. Lalu disusul mode kunjungan Family dan Friends.
- Wisata di Malang Jawa Timur merupakan cocok untuk mode kunjungan wisatawan Friends dilihat dari diagram diatas. Lalu disusul mode kunjungan Family dan Couple.
- Wisata di Yogyakarta DI Yogyakarta merupakan cocok untuk mode kunjungan wisatawan Friends dilihat dari diagram diatas. Lalu disusul mode kunjungan Couple dan Family.

##### EDA melihat mode kunjungan -> terhadap jenis wisata
"""

mode_tab = data_use_rating
crosstab_count2 = pd.crosstab(mode_tab['AttractionType'], mode_tab['VisitMode'])
crosstab_count2['count'] = crosstab_count2.sum(axis=1)
crosstab_count2.sort_values(by='count', ascending=False, inplace=True)
crosstab_count2

crosstab_count2 = crosstab_count2.drop(columns='count')
crosstab_count2.plot(kind='bar', figsize=(12, 8), width=0.8, color=['crimson', 'deeppink', 'mediumorchid', 'blueviolet','darkslateblue'])


plt.title('Distribusi ModeVisit per AttractionType', fontsize=16)
plt.xlabel('AttractionType', fontsize=12)
plt.ylabel('Jumlah', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.legend(title='Rating')


plt.tight_layout()
plt.show()

"""Bedasarkan 5 jenis wisata dengan jumlah pengunjung terbanyak, wisatawan Couple akan mengunjungi jenis wisata Nature Wilds Area, Beaches, Religious Sites, Points of Interest and Landmarks. Untuk kunjungan Family adalah jenis wisata Water Parks

Summary Visualisasi Data dalam rentang waktu Oktober 2022 - January 2023: Wisata berlokasi di Bali merupakan tujuan wisatawan terbanyak dibandingkan lokasi Malang Jawa Timur dan Yogyakarta area DI Yogyakarta. Wisata di Bali didominasi wisatawan adalah jenis wisata Nature & Wildlife Areas, Water Parks, Points of Interest & Landmarks, Religious Sites. Selain itu banyak pengunjung dengan tujuan daerah Bali dengan pengunjung Couple disusul pengunjung Familiy dan Friends. Sacred Monkey Forest Sactuary merupakan wisata Nature & Wildlife Areas terfavorit wisatawan dengan rating lebih dari 3 dari wisata di Bali lainnya.

### 4. Data Preparation

##### 4. 1 Data Prepertaion untuk Modelling Content Based -> Cosine Similarity

###### 4. 1. 1 Pre-processing data - Text Cleaning

Pada value kolom NewAttraction dan NewAttractionType setiap kata terdapat spasi, jika dilakukan mapping Vectorizer akan menampilkan value kolom yang tidak sesuai. Sehingga perlu cleaning teks pada simbol-simbol dan mengganti spasi dengan underscore
"""

df_content.head(5)

import re

def cleaningText(text):
  text = re.sub(r'-|\(|\)', '', text)
  text = re.sub(r'&', 'and', text)
  text = re.sub(r' ', '_', text)
  return text

df_content['NewAttraction'] = df_content['Attraction'].apply(cleaningText)
df_content['NewAttractionType'] = df_content['AttractionType'].apply(cleaningText)

"""###### 4. 1. 2 Melihat nilai Unik Item (gabungan) yang akan digunakan"""

print(len(df_content['NewAttraction']))
df_content['NewAttraction'].unique()

"""###### 4. 1. 3 Feature Engineering - TF-IDF Vectorizer

Step 1: Membersihkan nilai kolom string dan mengganti space menjadi underscore -> dimana agar membentuk fitur dari nama-nama unik yang diekstraksi dari semua nama di kolom NewAttraction.
"""

from sklearn.feature_extraction.text import TfidfVectorizer

tf = TfidfVectorizer()

tf.fit(df_content['NewAttraction'])

print(tf.get_feature_names_out())
len(tf.get_feature_names_out())

"""###### 4. 1. 4 Feature Engineering - Transfomasi nilai TF-IDF Vectorizer ke bentuk matrix

Step 2: Mentranformasi ke bentuk matrix sehingga terbentuk baris dari Step 1/nama-nama unik New ATtraction dan kolom sejumlah item yang akan digunakan sebagai content-based yaitu kolom NewAttractionType.
"""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(df_content['NewAttractionType'])

# Melihat ukuran matrix tfidf
print("jumlah baris dan kolom = ", tfidf_matrix.shape)
print(tfidf_matrix)

"""Membentuk Data Frame dengan index dari nilai-nilai Attraction (nama wisata) dan kolom dari nilai-nilai Attraction Type (jenis wisata). Jika nilai 1 merupakan nilai index (Attraction/wisata) yang memiliki jenis tersebut pada kolom (AttractionType/jenis wisata)


"""

df = pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=df_content.NewAttraction
)#.sample(22, axis=1).sample(10, axis=0)
df

"""##### 4. 2 Data Preparation untuk Modelling Collaborative Based -> Neural Network RecommenderNet

###### 4. 2. 1 Mengokonversi nilai nilai yang akan digunakan untuk input model dalam bentuk angka -> menggunakan encoding

- Nilai kolom UserId
"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = data_use_rating['UserId'].unique().tolist()
print('list UserId: ', user_ids)

# Proses encoding userID -> UserId : Encode
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded UserId : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID -> Encode : UserId
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke UserId: ', user_encoded_to_user)

"""- Nilai kolom AttractionId"""

# Mengubah placeID menjadi list tanpa nilai yang sama
att_ids = data_use_rating['AttractionId'].unique().tolist()

# Melakukan proses encoding AttractionId -> AttractionId : Encode
att_to_att_encoded = {x: i for i, x in enumerate(att_ids)}
print('encoded AttractionId : ', user_to_user_encoded)
# Melakukan proses encoding angka ke AttractionId -> Encode : AttractionId
att_encoded_to_att = {i: x for i, x in enumerate(att_ids)}
print('encoded angka ke AttractionId: ', att_encoded_to_att)

"""###### 4. 2. 2 Melakukan mapping nilai encoded ke data yang akan digunakan"""

data_use_rating['user'] = data_use_rating['UserId'].map(user_to_user_encoded)


data_use_rating['att'] = data_use_rating['AttractionId'].map(att_to_att_encoded)
data_use_rating

"""###### 4. 2. 3 Melihat jumlah UserId, AttractionID dan Rating sebagai atribut yang akan digunakan"""

import numpy as np

num_users = len(user_to_user_encoded)
print(num_users)


num_att = len(att_encoded_to_att)
print(num_att)

# Mengubah rating menjadi nilai float
data_use_rating['Rating'] = data_use_rating['Rating'].values.astype(np.float32)

# Nilai minimum rating
min_rating = min(data_use_rating['Rating'])

# Nilai maksimal rating
max_rating = max(data_use_rating['Rating'])

print('Number of User: {}, Number of Attraction: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_att, min_rating, max_rating
))

"""###### 4. 2. 4 Data Splitting rasio 80:20"""

data_use_rating = data_use_rating.sample(frac=1, random_state=42)
data_use_rating

x = data_use_rating[['user', 'att']].values
y = data_use_rating['Rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * data_use_rating.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

print(len(x_train))
print(len(x_val))

"""##### 4. 3 Data Preparation untuk Modelling Collaborative Based -> SVD

##### 4. 3. 1 Menginstall library untuk implementasi algortima SVD
"""

pip install scikit-surprise

from surprise import SVD, Dataset, Reader
from surprise.model_selection import cross_validate

"""##### 4. 3. 2 Persiapan data yang akan digunakan"""

data_use_rating

data_SVD = data_use_rating[['UserId', 'AttractionId', 'Rating']]
data_SVD

"""##### 4. 3. 3 Mengubah DataFrame menjadi format standar library Suprise dan membuat skala rating 1-5 untuk"""

reader = Reader(rating_scale=(1, 5))
data_SVD_use = Dataset.load_from_df(data_SVD, reader)
trainset = data_SVD_use.build_full_trainset()

print("Data pengguna-item dalam trainset:")
for uid, iid, true_r in trainset.all_ratings():
    print(f"UserId: {uid}, AttId: {iid}, Rating: {true_r}")

"""###### 5. Build Model

#### 5. 1 Content Based

##### 5. 1. 1 Build Model menggunakan Cosine Similarity

###### 5. 1. 1. 1 Menghitung nilai kesamaan antar item yang digunakan -> Cosine Similarity

Cosine similarity mengukur kesamaan antara dua vektor dan menentukan apakah kedua vektor tersebut menunjuk ke arah yang sama. Ia menghitung sudut cosinus antara dua vektor. Semakin kecil sudut cosinus, semakin besar nilai cosine similarity.
Pada step ini menghitung kesamaan antara NewAttraction (nama wisata) dengan NewAttraction (nama wisata) lainnya berdasarkan kesamaan pada item NewAttractionType. Sehingga nilai 1 merupakan nilai suatu NewAttraction (nama wisata) memiliki kesamaan item (NewAttractionType) antar NewAttraction (nama wisata) lainnya. Sebaliknya nilai 0 tidak memiliki kesamaan sama sekali
"""

from sklearn.metrics.pairwise import cosine_similarity

# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

cosine_sim_df = pd.DataFrame(cosine_sim, index=df_content['NewAttraction'], columns=df_content['NewAttraction'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df#.sample(5, axis=1).sample(10, axis=0)

"""###### 5. 1. 1. 2 Build Model -> Content-based filtering

step ini membangun model meggunakan top-N recommendation untuk memberikan sejumlah rekomendasi attraction pada pengguna yang diatur dalam parameter k (k: jumlah top k yang memiliki kesamaan terdekat dengan input)
"""

def attraction_recommendations(NewAttraction, similarity_data=cosine_sim_df, items=df_content[['NewAttraction', 'NewAttractionType', 'AttractionAddress']], k=10):

    index = similarity_data.loc[:,NewAttraction].to_numpy().argpartition(
        range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1].flatten()]
    closest = closest.drop(NewAttraction, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

df_content[df_content.NewAttraction.eq('Sanur_Beach')]

"""###### 5. 1. 1. 3 Hasil model sistem rekomendasi Content-based Cosine Similarity"""

Attraction = 'Sanur Beach'
Attraction = Attraction.replace(' ', '_')
Attraction

recommendation_10 = attraction_recommendations(Attraction)
recommendation_10['NewAttraction'] = recommendation_10['NewAttraction'].str.replace('_', ' ')
recommendation_10['NewAttractionType'] = recommendation_10['NewAttractionType'].str.replace('_', ' ')
recommendation_10 = recommendation_10[['NewAttraction', 'NewAttractionType', 'AttractionAddress']]

recommendation_10

def recommendation_content1(Attraction):
  Attraction = Attraction.replace(' ', '_')
  recommendation_10 = attraction_recommendations(Attraction)
  recommendation_10['NewAttraction'] = recommendation_10['NewAttraction'].str.replace('_', ' ')
  recommendation_10['NewAttractionType'] = recommendation_10['NewAttractionType'].str.replace('_', ' ')
  recommendation_10 = recommendation_10[['NewAttraction', 'NewAttractionType', 'AttractionAddress']]
  n=0
  print("="*100)
  print("Recommendation System Content Based-Cosine Similarity")
  print("="*100)
  print("="*100)
  print("10 places to go based on item -->", Attraction.replace('_', ' '))
  print("="*100)
  for index, row in recommendation_10.iterrows():
    n+=1
    print(n, row.NewAttraction, ':', row.AttractionAddress)

"""**Manampilkan rekomendasi Top 10 Wisata -  content based Cosine Similarity**"""

recommendation_content1('Sanur Beach')

"""#### 5. 2 Collaborative Based

##### 5. 2. 1 Build Model menggunakan Neural Network RecommenderNet
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

"""###### 5. 2. 1. 1 Membuat parameter fungsi Neural Network"""

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_att, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_att = num_att
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-8)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.att_embedding = layers.Embedding( # layer embeddings attraction
        num_att,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-8)
    )
    self.att_bias = layers.Embedding(num_att, 1) # layer embedding attractioon bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    att_vector = self.att_embedding(inputs[:, 1]) # memanggil layer embedding 3
    att_bias = self.att_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_att = tf.tensordot(user_vector, att_vector, 2)

    x = dot_user_att + user_bias + att_bias

    return tf.nn.sigmoid(x) # activation sigmoid

model_nn = RecommenderNet(num_users, num_att, 35)
model_nn.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError(),tf.keras.metrics.MeanAbsoluteError]
)

"""###### 5. 2. 1. 2 Training Model"""

# Memulai training

history = model_nn.fit(
    x = x_train,
    y = y_train,
    batch_size = 32,
    epochs = 15,
    validation_data = (x_val, y_val)
)

"""###### 5. 2. 1. 3 Menampilkan grafik berdasarkan RMSE dan MAE"""

#Diagram of rmse and mae training and testing
import matplotlib.pyplot as plt

rmse1_tr = history.history['root_mean_squared_error']
rmse1_ts = history.history['val_root_mean_squared_error']

mae1_tr = history.history['mean_absolute_error']
mae1_ts = history.history['val_mean_absolute_error']

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

ax1.plot(rmse1_tr, color='blue')
ax1.plot(rmse1_ts, color='orange')
ax1.set_title('model_metrics rmse')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
ax1.legend(['train', 'val'], loc='upper left')

ax2.plot(mae1_tr, color='blue')
ax2.plot(mae1_ts, color='orange')
ax2.set_title('model_metrics mae')
plt.ylabel('mean_absolute_error')
plt.xlabel('epoch')
ax2.legend(['train', 'val'], loc='upper left')

plt.tight_layout()
plt.show()

"""Nilai RMSE training pada epochs terakhir menunjukkan 0.19 dan testing nilai RMSE 0.23. Dimana selama training nilai RMSE menurun dan begitu nilai MAE dapat diartikan error semakin kecil

###### 5. 2. 1. 4 Hasil Model
"""

att_df = data_use_rating
user_id = data_use_rating.UserId.sample(1).iloc[0]
att_visited_by_user = data_use_rating[data_use_rating.UserId == user_id]
att_visited_by_user

att_not_visited = att_df[~att_df['AttractionId'].isin(att_visited_by_user.AttractionId.values)]['AttractionId']

att_not_visited_2 = list(
    set(att_not_visited)
    .intersection(set(att_to_att_encoded.keys()))
)

att_not_visited_3 = [[att_to_att_encoded.get(x)] for x in att_not_visited_2]

user_encoder = user_to_user_encoded.get(user_id)
user_att_array = np.hstack(
    ([[user_encoder]] * len(att_not_visited_3), att_not_visited_3)
)

rec_dest = data_use_rating[['AttractionId','Attraction', 'AttractionType', 'VisitMode', 'AttractionAddress', 'att']]
rec_dest = rec_dest.drop_duplicates('att').sort_values(by='att')

"""**Manampilkan rekomendasi Top 10 Wisata - collaborative Neural Network RecommenderNet**"""

ratings = model_nn.predict(user_att_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_att_ids = [
    att_encoded_to_att.get(att_not_visited_3[x][0]) for x in top_ratings_indices
]


print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Recent destinattion with high ratings from user')
print('----' * 8)


top_att_user = (
    att_visited_by_user.sort_values(
        by = 'Rating',
        ascending=False
    )
    .head(5)
    .att.values
)
att_df_rows = rec_dest[rec_dest['att'].isin(top_att_user)]
for row in att_df_rows.itertuples():
    print('[',row.AttractionType,']',row.Attraction, ':', row.AttractionAddress)
print('----' * 8)
print('10 places to go - recommended')
print('----' * 8)
recommended_att = rec_dest[rec_dest['AttractionId'].isin(recommended_att_ids)]
n = 0
for row in recommended_att.itertuples():
    n+=1
    print(n, '[',row.AttractionType,']',row.Attraction, ':', row.AttractionAddress)

"""##### 5. 2. 2 Build Model menggunakan Algortima SVD

SVD (Singular Value Decomposition) merupakan algoritma untuk sistem rekomendasi, terutama untuk menangani collaborative filtering berbasis matriks dekomposisi

Data yang telah dikonversi menjadi format struktur library Surprise akan dilatih menggunakan SVD, dan membentuk prediksi skor baru berdasarkan pelatihan data yang telah diformat struktur library Surprise

Training model akan menggunakan cross validation sebanyak 10 folds dan melihat metrik RMSE dan MAE

###### 5. 2. 2. 1 Membuat variabel model -> model menggunakan SVD(Singular Value Decomposition)
"""

model = SVD()

"""###### 5. 2. 2. 2 Melakukan Cross-Validation menggunakan 10 folds"""

results = cross_validate(model, data_SVD_use, measures=['RMSE', 'MAE'], cv=10, verbose=True)
results

"""Berdasarkan nilai RMSE dari folds 1-10 menunjukkan nilai kecil yaitu 0.9 (dibawah 1, jika semakin besar cth 2.xx/5.xx maka buruk) dapat dikatakan prediksi baik. Dan nilai MAE yang kecil. Nilai STD menunjukkan nilai kecil sehingga hasil nilai MSE dan MAE masing-masing folds konsisten.

###### 5. 2. 2. 3 Hasil Model
"""

user_id

att_visited_by_user

"""Membuat data frame destinasi wisata yang belum dikunjungan dan membuat prediksi rating baru"""

att_not_visited_SVD = item_joined[~item_joined['AttractionId'].isin(att_visited_by_user.AttractionId.values)]
att_not_visited_SVD.sort_values(by='AttractionId')

"""Memprediksi skor baru pada wisata (NewAttraction) yang belum dikunjungi. 10 prediksi baru teratas akan menjadi rekomendasi untuk user yang belum pernah dikunjungi"""

trainset = data_SVD_use.build_full_trainset()
model.fit(trainset)

att_not_visited_SVD['Estimate_Score'] = att_not_visited_SVD['AttractionId'].apply(lambda x: model.predict(user_id, x).est)

att_not_visited_SVD = att_not_visited_SVD.drop(['AttractionId','AttractionCityId','AttractionTypeId'], axis = 1)

att_not_visited_SVD = att_not_visited_SVD.sort_values('Estimate_Score', ascending=False)
att_not_visited_SVD.reset_index(drop=True, inplace=True)
att_not_visited_SVD = att_not_visited_SVD.head(10) #top N recommendation (10 top)
att_not_visited_SVD

"""**Manampilkan rekomendasi Top 10 Wisata - collaborative based SVD**"""

print('Showing recent for users: {}'.format(user_id))
print('---' * 20)
for row_user_recent in att_visited_by_user.itertuples():
    print('[',row_user_recent.AttractionType,']',row_user_recent.Attraction, ':', row_user_recent.AttractionAddress)

print('===' * 50)
print('===' * 50)
print('10 places to go - probably you sholud like')
print('---' * 20)
x = 0
for row_user_predict in att_not_visited_SVD.itertuples():
    x+=1
    print(x,'[',row_user_predict.AttractionType,']',row_user_predict.Attraction, ':', row_user_predict.AttractionAddress)



"""###### 6. Evaluasi

Metrik pada model sistem rekomendasi berfokus pada RMSE dan MAE. RMSE merupakan mengukur akar dari rata-rata kuadrat selisih antara nilai prediksi dan nilai aktual, sehingga dapat menekankan kesalahan yang lebih besar, karena nilai kesalahan dikuadratkan. Sehingga dengan nilai RMSE kecil menunjukkan nilai error yang kecil juga
Selain itu metrik MAE digunakan untuk mengukur kesalahan dengan nilai rata-rata absolut antara nilai prediksi dan nilai aktual. MAE membantu mengukur seberapa besar rata-rata perbedaan antara nilai aktual dan nilai prediksi. Dengan nilai MAE yang semakin kecil menunjukkan nilai kedua tersebut memiliki error yang kecil

1. Content based
Berdasarkan 2 teknik untuk menemukan pola hubungan antar item, penggunaan cosine_similarity dapat menunjukkan item yang memiliki kesamaan dengan item yang diinput. Cosine similarity merupakan metrik untuk mengukur kemiripan antara 2 vector dimana berdasarkan sudut kosinus. Pada atribut yang memiliki nilai 1 merupakan atribut yang memilki kesamaan sedangkan nilai 0 atribut tidak memiliki kesamaan
Hasil pengembangan menggunakan metode cosine similarity dapat menunjukkan 10 rekomendasi yang relate dengan input. Metode cosine similarity lebih memiliki kesamaan yang lebih dekat karena menggunakan skor kesamaan berbasis vektor dan kedua atribut memiliki hubungan/lineraritas (jenis wisata dan tempat wisata)


2. Collaborative based
Hasil penggunaan 2 algoritma adalah model dapat merekomendasi destinasi wisata. Pada penggunaan Neural Network menunjukkan nilai error MAE dan RMSE yang semakin rendah sekitar 0.19 sedangkan algoritma SVD sekitar 0.9-0.7. Algoritma NN dapat menunjukkan 10 rekomendasi teratas menyesuaikan jenis wisata yang mirip, frekuensi destinasi wisata yang banyak dikunjungi wisatawan dan rating detinasi wisata (membandingkan melihat hasil EDA-seperti jenis wisata yang sering muncul)
Pada algoritma SVD 10 rekomendasi teratas berdasarkan prediksi baru dari perhitungan fitur laten rating dan destinasi wisata. Sehingga rekomendasi menunjukkan destinasi wisata dengan kemiripan wisata yang tesembunyi (tidak terlalu menonjol dapat dilihat dengan perbandingan EDA) dan menghasilkan prediksi rating baru yang kemungkinan akan mirip dengan riwayat destinasi wisatawan. Sehingga model ini cocok untuk mengenalkan wisata baru.
Pada projek ini hasil sistem rekomendasi penggunaan algoritma NN menunjukkan nilai RMSE dan MAE lebih rendah dibandingkan menggunakan algoritma SVD. Selain itu hasil algoritma NN mendekati dengan hasil EDA dimana dengan jenis wisata dan destinasi wisata yang direkomendasikan sering muncul dan mendekati dengan jumlah rating yang tingga pada data, sesuai banyaknya riwayat kunjungan tiap pengunjung. Sedangkan SVD perlu dievaluasi kembali dan eksplore lagi pada proses training model karna saat ini menggunakan cross-validaton dan pengkonversian data yang menggunakan library surprise dan fitur laten.

Hasil pengembangan/proyek ini dapat menjawab probelm statement yang dijelaskan pada Business Undestanding sebagai berikut:
1. **Bagaimana langkah-langkah untuk membuat sistem rekomendasi untuk calon pengunjung berdasarkan referensi riwayat pengunjung?**
= Langkah membuat sistem rekomendasi adalah dengan metode sederhana CRISP-DM (Cross-Industry Standard Process for Data Mining) yaitu melakukan pengumpulan data, membersihkan data dan mempersiapkan data yang akan digunakan, mengimplementasi berdasarkan content-based dan collaborative-based, dan menetukan model berdasarkan MAE dan MSE pada sistem rekomdeasi collaborative-based. Hasil pengembangan model akan menghasilkan output top 10 rekomendasi berdasarkan input wisata yang diberikan.
2. **Bagaimana atribut-atribut referensi pengunjung-pengunjung untuk menentukan destinasi wisata?**
= Dengan menganalisis dan melihat visualisasi data kunjungan wisata. Analisis menunjukkan daerah wisata, tempat wisata, dan jenis kunjungan yang menjadi rekomendasi calon pengunjung. Berdasarkan pengembangan projek ini daerah Bali merupakan daerah favorit bagi pengunjung couple. Selain itu wisata di Bali, jenis atraksi Nature & Wildlife Areas merupakan jenis atraksi yang disukai banyak wisatawan.
3. **Bagaimana cara membangun model Machine Learning sebagai solusi untuk merekomendasikan destinasi wisata untuk calon pengunjung berdasarakan preferensi pengunjung tersebut?**
= Setelah melakukan pengembangan CRISP-DM, akan menentukan berdasarkan nilai MAE dan MSE yang menunjukkan nilai error yang paling kecil. Pada metode content-based metode cosine similarity lebih cocok dengan kondisi data saat ini yang mana 2 atribut yang memiliki hubungan linear. Untuk metode collaborative-based menggunakan Neural Network RecommenderNet dari Library keras menampilkan nilai RMSE MAE sekitar 0.20, sedangkan menggunakan SVD dari library Surprise menampilkan nilai RMSE MAE sekitar 0.80. Dengan arti model Neural network RecommenderNet menunjukkan nilai MAE RMSE lebih rendah. Maka implementasi lebih baik menggunakan Neural Network

Poin-poin diatas dapat menjawab goals dimana:
1. Dapat merekomendasikan tujuan wisata sesuai prefernsinya berdasarkan referensi riwayat pengunjung-pengunjung sebelumnya yang memiliki kesamaan preferensi tujuan wisata,
2. Dapat melihat atribut referensi pengunjung untuk menentukan destinasi wisata,
3.  Dapat meningkatkan kepuasan para pengunjung wisaata sesuai preferensinya berdasarkan hasail sistem rekomendasi,
4. Dapat mengurangi penilaian rendah pada destinasi wisata karena wisata yang dituju akan sesuai referensi calon wistawan,
5. Dapat meningkatkan daya tarik wisata di Indonesia dan menaikkan pendapatan untuk pekerja dan sektor ekonomi negara

Solusi proses pengembangan/penilitian yang diterapkan projek ssitem rekomendasi destinasi wisata dapat berdampak besar untuk menaikkan daya tarik wisata untuk calon wisatawan dan dapat menaikkan perekonomian dari sektor pariwisata di Indonesia.
"""



